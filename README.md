# ğŸ½ï¸ Swiggy Food Delivery Analysis | Data Analytics & SQL

## ğŸ“Œ Project Overview

This project delivers an **end-to-end data analytics solution** for analyzing Swiggy food delivery orders across multiple **states, cities, restaurants, and cuisines**. The objective is to transform raw transactional data into **actionable business intelligence** using **advanced SQL** and a well-structured **Star Schema data warehouse**.

The solution enables insights into **revenue performance, customer spending behavior, food trends, and operational efficiency** through scalable dimensional modeling and analytical queries.

---

## ğŸ› ï¸ Tools & Technologies

* **SQL Server** â€“ Data querying and analytics
* **Advanced SQL** â€“ JOINs, aggregations, window functions
* **Data Modeling** â€“ Star Schema (Fact & Dimension tables)
* **Business Intelligence Concepts** â€“ KPIs, trend analysis

---

## ğŸ“‚ Dataset Description

The dataset consists of Swiggy food delivery order records containing:

* Order date and time
* State, city, and delivery location
* Restaurant name
* Food category and dish name
* Dish price (INR)
* Customer ratings and rating counts

Each record represents a **single dish ordered** within a customer order.

---

## ğŸ§¹ 1. Data Cleaning & Validation

To ensure analytical accuracy and reliability, the following steps were performed:

* Conducted **null value checks** and column-level data quality validation
* Identified and removed **duplicate records** using `ROW_NUMBER()` window function
* Handled **blank and empty string values** across categorical fields
* Ensured clean, consistent data before dimensional modeling

âœ” Result: Reliable and analysis-ready dataset

---

## ğŸ—ï¸ 2. Dimensional Modeling (Star Schema)

A scalable **Star Schema** was designed to support fast querying and flexible reporting.

### ğŸ”¸ Dimension Tables

* **Dim_Date** â€“ Date, month, quarter, year attributes
* **Dim_Location** â€“ State, city, delivery location
* **Dim_Restaurant** â€“ Restaurant details
* **Dim_Category** â€“ Food categories / cuisines
* **Dim_Dish** â€“ Individual dish information

### ğŸ”¹ Fact Table

* **Fact_Swiggy** â€“ Central fact table storing price, ratings, and foreign keys

### âœ… Modeling Outcomes

* Reduced data redundancy
* Improved query performance
* Enabled efficient time, location, and product-level analysis

---

## ğŸ“Š 3. Analytics & Business Intelligence

### ğŸ“ˆ Key Performance Indicators (KPIs)

* **Total Orders**
* **Total Revenue (â‚¹ Million)**
* **Average Dish Price**
* **Average Rating**

### ğŸ“… Temporal Analysis

* Monthly, quarterly, and yearly order trends
* Order distribution by **day of the week**

### ğŸ“ Location-Based Insights

* **Top 10 cities** by order volume
* **State-wise revenue contribution**

### ğŸ› Food & Restaurant Performance

* Top 10 restaurants by number of orders
* Top food categories by **revenue** and **order volume**
* Most ordered dishes
* Cuisine performance using **orders and average ratings**

### â­ Customer Spending Analysis

* Order distribution across price ranges:

  * Under â‚¹100
  * â‚¹100â€“199
  * â‚¹200â€“299
  * â‚¹300â€“499
  * â‚¹500+

### ğŸŒŸ Ratings Analysis

* Distribution of dish ratings (1â€“5)

---

## ğŸ› ï¸ 4. Technical Skills Demonstrated

* **Advanced SQL:** JOINs, GROUP BY, aggregations
* **Window Functions:** ROW_NUMBER(), PARTITION BY
* **Date Functions:** YEAR(), MONTH(), DATEPART(), DATENAME()
* **Conditional Logic:** CASE statements
* **Data Modeling:** Star Schema, fact & dimension table design
* **Query Optimization:** Efficient queries for large datasets

---

## ğŸ“‰ 5. Business Impact

* Enabled **data-driven decision-making** with clean and structured data
* Improved reporting speed and flexibility using dimensional modeling
* Delivered clear insights into **sales trends, customer behavior, and cuisine performance**
* Helped identify **high-performing locations, restaurants, and dishes**

---

## ğŸš€ Future Enhancements

* Integrate BI tools such as **Power BI / Tableau** for dashboarding
* Automate ETL pipelines for real-time data updates
* Perform customer segmentation and cohort analysis
* Add predictive analytics for demand forecasting

---

## ğŸ“ How to Use This Repository

1. Review SQL scripts for data cleaning, modeling, and analysis
2. Explore schema design for understanding dimensional modeling
3. Use analytical queries and insights for interview discussions or business case studies

---

## ğŸ‘¤ Author

**Subhash Naidu Gogineni**
Aspiring Data Analyst / Data Science Intern

---

â­ If you found this project insightful, consider starring the repository!

